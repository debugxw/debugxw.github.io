---
title: 分布式锁
excerpt: 一种在分布式系统中协调多个节点之间并发访问共享资源的机制
date: 2022-04-08
tags: [并发,分布式]
image: /img/theme/023.jpg
---

我们在系统中修改已有数据时，需要先读取，然后进行修改保存，此时很容易遇到并发问题。由于修改和保存不是原子操作，在并发场景下，部分对数据的操作可能会丢失。在单服务器系统我们常用本地锁来避免并发带来的问题，然而，当服务采用集群方式部署时，本地锁无法在多个服务器之间生效，这时候保证数据的一致性就需要用到分布式锁

要想在分布式环境中实现加锁操作，那么我们就必须借助一个外部系统来实现**互斥**的能力。这个外部系统可以是Redis、Zookeeper或者MySQL，而为了追求更高的性能，我们一般选用Redis或者Zookeeper

## 一、Redis实现

对于单机版的锁来说，使用方式一般分为三步：
1. 加锁
2. 执行业务操作
3. 释放锁

当使用Redis来实现分布式锁时，也是一样的道理，我们可以通过尝试设置某个key的值是否成功来判断是否成功或得锁，例如：
```bash
# nx 只有在key不存在的情况下才设置
# ex 过期时间，单位秒
set 'lock' 'val' nx ex 10 
do something
del 'lock'
```

### 锁过期时间问题
这里设置过期时间的目的是防止死锁的发生，假设在业务执行过程中程序异常退出，并没有释放锁，如果没有设置过期时间，那么这个锁就会被一直占用，形成死锁。
而添加过期时间也会带来一个问题，那就是这个过期时间设置成多少合适呢？
+ 如果时间设置短了，业务逻辑还没有执行完成key就过期了，恰巧这时另一个客户端来执行加锁操作，那么这个互斥锁就会同时被两个客户端占用，这显然是有问题的
+ 如果时间设置过长，业务执行过程异常退出，锁却并未释放，只有等到锁过期，而在这个过程中，其他想要拿到锁的客户端只能白白等待

如何解决这个问题呢？
既然无法准确评估过期时间该设置为多少，那么我们就定时去检测。一种解决方案是先给锁设置一个较短过期时间，在拿到锁之后，启动一个定时任务去检测锁的过期时间，如果锁快要过期了，但是业务还没有执行完成，那么就重新设置锁的过期时间，相当于是给锁执行一个**续期**操作。一些三方工具已经帮助我们实现了这些功能，比如Redisson

### 错误释放锁
上面的加锁解锁操作其实还有一点小问题，如下所示：

![](../../../../img/distributed/redis_lock_%E8%AF%AF%E9%87%8A%E6%94%BE.png)

假设当前clientA占有锁，在t1时刻，clientA执行完业务操作，但还未释放锁，并且锁刚好过期。在 t2 时刻 clientB 尝试去获取锁，因为clientA占用的锁已过期，所以clientB能够获取到锁。接下来clientA执行到释放锁这个操作，但是clientA并不知道此时锁已经被clientB占用，所以clientB占用的锁会被错误的释放。接下来如果有其他的客户端再来尝试获取锁（例如t3时刻clientC来获取锁），也是可以成功的，那么就同时存在两个客户端持有锁，显然是不安全的！

解决方案：**客户端在设置锁时，添加一个唯一标识**，如下：
```bash
set 'lock' 'clientA_timestamp' nx ex 10 
do something
Lua start
    if get('lock') == 'clientA_timestamp'
        del 'lock'
Lua end
```
在释放锁的时候，先判断锁是不是自己加的，如果是，再释放，这样就可以避免锁被错误释放的问题
这里的Lua是一种脚本语言，它可以确保最后的```if```和```del```成为一个原子操作（如果没有lua，最后的```if```和```del```就不是一个原子操作，在极端的情况下，还是会出现上面的问题，比如锁在```if```操作之后、```del```操作之前过期，那么 clientB 就可以在```if```和```del```之间进行加锁操作，后面 clientA 的```del```操作也会错误的释放 clientB 的锁）

### 集群带来的安全性问题
我们在使用Redis时，一般都会采用**集群+哨兵**的部署方式，这种部署方式的好处是可用性高、扩展性好，但这也同时提高了系统的复杂度。这时如果主节点挂掉，那么就有可能出现两个客户端同时持有锁的情况，如下：

![](../../../../img/distributed/redis_lock_cluster_problem.png)

+ t1：clientA尝试从master节点获取锁，成功则直接返回（因为Redis的主从复制是异步的，所以并不会等待数据同步至从节点才返回）
+ t2：master宕机，发生主从切换（**此时clientA获取的锁数据还未复制至从节点，主从切换就会导致锁数据丢失**）
+ t3：clientB尝试从new_master节点获取锁成功（因为之前的锁数据丢失了，所以clientB能成功拿到锁）

可以看到，在主从模式下，用Redis实现分布式锁是不安全的。这里的主要原因在于**Redis主从复制是异步的**，如果把它改为同步的方式也就可以避免上面的问题，但是Redis并没有提供同步的主从复制方式，而如果我们直接去改源码，代价又太大，最重要的是同步的主从复制方式还会降低 Redis 的响应时间。那有没有一种更好的解决方案呢？
好在Redis的作者提出了一种名为**RedLock**的方案，但它真的可以保证绝对的安全吗？

### RedLock
在使用RedLock时，我们需要部署多个实例（它们之间是没有任何关系的，都是一个个孤立的实例），官方推荐5个，具体加锁步骤为：

<center><image src="../../../../img/distributed/redis_red_lock.png" width="60%" height="60%"/></center>

1. 客户端先获取**当前时间戳T1**
2. 客户端依次向这5个Redis实例发起加锁请求，且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个Redis实例申请加锁
3. 如果客户端从>=3个（大多数）Redis 实例上加锁成功，则再次获取**当前时间戳T2**，如果 T2 - T1 < 锁的过期时间。此时，认为客户端加锁成功，否则认为加锁失败
4. 加锁成功，则执行业务逻辑操作
5. 加锁失败，则向**全部节点**发起释放锁请求（前面讲到的Lua脚本先判断再释放锁）

RedLock的关键点在于**当加锁成功实例数量超过多数时，那么就可以认为加锁成功**。
为什么大多数实例加锁成功就可以认为是加锁成功了呢？因为多个Redis实例一起来用，其实就组成了一个**分布式系统**。在分布式系统中，总会出现**异常节点**，所以，在谈论分布式系统问题时，需要考虑异常节点达到多少个，也依旧不会影响整个系统的**正确性**。这是一个分布式系统**容错**问题，这个问题的结论是：**如果只存在**故障**节点，只要大多数节点正常，那么整个系统依旧是可以提供正确服务的**。例如像Zookeeper的ZAB协议其实就是使用的类似的设计思想，这个问题的模型，就是我们常听到的**拜占庭将军**问题。

### Martin对于RedLock的质疑
Redis作者的这个方案一经提出，就受到了分布式领域专家Martin的质疑，主要阐述了以下几点：

#### 1、分布式锁的目的是什么
Martin表示，首先你要清楚使用分布式锁的目的是什么，他认为有两点：
1. **效率**：使用分布式锁的互斥能力，是避免不必要地做同样的两次工作（例如一些昂贵的计算任务）。即使锁失效，也并不会带来恶性的后果，无非就是多做了一次计算而已，例如统计了两次月数据、发了两次邮件等，无伤大雅
2. **正确性**：使用锁用来防止并发进程互相干扰。如果锁失效，会造成多个进程同时操作同一条数据，产生的后果是数据严重错误、永久性不一致、数据丢失等恶性问题，就像给患者服用了重复剂量的药物，后果很严重

他认为，如果你是为了效率，那么直接使用单实例的Redis就够了，即使偶尔发生的锁失效问题，也不会产生严重的后果。而使用RedLock太重，完全没有必要。
如果你是为了正确性，Martin认为Redlock根本达不到安全性的要求，也依旧存在锁失效的问题！

#### 2、锁在分布式系统中会遇到的问题
Martin表示，一个分布式系统，更像是一个复杂的野兽，存在着你想不到的各种异常情况。这些异常场景主要包括三大块，这也是分布式系统会遇到的三座大山：NPC
+ N：Network Delay，网络延迟
+ P：Process Pause，进程暂停（例如GC）
+ C：Clock Drift，时钟漂移

Martin用一个进程暂停（GC）的例子，指出了Redlock存在的安全性问题：
1. clientA请求锁定节点A、B、C、D、E
2. clientA的拿到锁后，进入GC（时间比较久）
3. 所有Redis节点上的锁都过期了
4. clientB获取到了A、B、C、D、E上的锁
5. clientA GC结束，认为成功获取锁
6. clientB也认为获取到了锁，发生冲突

<center><image src="../../../../img/distributed/redis_red_lock_time.png" width="60%" height="60%"/></center>

Martin认为，GC可能发生在程序的任意时刻，而且执行时间也是不可控的。
仔细想想，这个问题其实和上文提到的[**锁过期时间问题**](https://debugxw.github.io/2022/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/#%E9%94%81%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E9%97%AE%E9%A2%98)有点类似，**锁过期时间问题**我们可以使用**续期**操作来避免，但是RedLock却没有类似的机制

#### 3、假设时钟正确是不合理的
又或者，当多个Redis节点**时钟**发生问题时，也会导致Redlock锁失效，例如：

<center><image src="../../../../img/distributed/redis_red_lock_process_pause.png" width="60%" height="60%"/></center>

1. clientA获取节点A、B、C上的锁，但由于网络问题，无法访问D和E
2. 节点C上的时钟**向前跳跃**，导致锁到期
3. clientB获取节点C、D、E上的锁，由于网络问题，无法访问A和B
4. clientA和clientB现在都相信它们持有了锁（冲突）

Martin觉得，Redlock必须强依赖多个节点的时钟是保持同步的，一旦有节点时钟发生错误，那这个算法模型就失效了。即使C不是时钟跳跃，而是崩溃后立即重启，也会发生类似的问题。
Martin继续阐述，机器的时钟发生错误，是很有可能发生的：
+ 系统管理员手动修改了机器时钟
+ 机器时钟在同步NTP时间时，发生了大的跳跃

总之，Martin认为，Redlock的算法是建立在**同步模型**基础上的，有大量资料研究表明，同步模型的假设，在分布式系统中是有问题的。在混乱的分布式系统的中，你不能假设系统时钟就是对的，所以，你必须非常小心你的假设。

#### 4、fecing token方案，保证正确性
相对应的，Martin提出一种被叫作fecing token的方案，保证分布式锁的正确性。这个模型流程如下：

<center><image src="../../../../img/distributed/redis_red_lock_fecing_token.png" width="60%" height="60%"/></center>

1. 客户端在获取锁时，锁服务可以提供一个递增的token
2. 客户端拿着这个token去操作共享资源
3. 共享资源可以根据token拒绝后来者的请求

这样一来，无论NPC哪种异常情况发生，都可以保证分布式锁的安全性，因为它是建立在**异步模型**上的。而Redlock无法提供类似fecing token的方案，所以它无法保证安全性。（fecing token本质上有点类似于[CAS](https://debugxw.github.io/2019/04/26/Compare-and-Swap/)操作）
他还表示，一个好的分布式锁，无论NPC怎么发生，都可以不在规定时间内给出结果，但并不会给出一个错误的结果。也就是只能够影响到锁的**性能**，而不能够影响它的**正确性**

**Martin的结论：**
1. **Redlock不伦不类：**对于效率来讲，Redlock比较重，没必要这么做，而对于正确性来说，Redlock是不够安全的
2. **时钟假设不合理：**该算法对系统时钟做出了危险的假设（假设多个节点机器时钟都是一致的），如果不满足这些假设，锁就会失效
3. **无法保证正确性：**Redlock不能提供类似fencing token的方案，所以解决不了正确性的问题。为了正确性，请使用有**共识系统**的软件，例如Zookeeper

好了，以上就是Martin反对使用Redlock的观点，看起来有理有据。下面我们来看Redis作者Antirez是如何反驳的

### Redis作者Antirez的反驳
在Antirez的反驳文章中，重点阐述了以下三点：

#### 1、解释时钟问题
首先，Antirez一眼就看穿了对方提出的最为核心的问题：时钟问题。
他表示，Redlock并不需要完全一致的时钟，只需要大体一致就可以了，**允许有误差**。
例如要计时5s，但实际可能记了4.5s，之后又记了5.5s，有一定误差，但只要不超过**误差范围**（锁失效时间）即可，这种对于时钟的精度要求并不是很高，而且这也符合现实环境。对于对方提到的时钟修改问题，Redis作者反驳到：
+ **手动修改时钟：**不要这么做就好了，否则你直接修改Raft日志，那Raft也会无法工作...
+ **时钟跳跃：**通过**恰当的运维**，保证机器时钟不会大幅度跳跃（每次通过微小的调整来完成），实际上这是可以做到的

> 为什么Redis作者优先解释时钟问题？因为在后面的反驳过程中，需要依赖这个基础做进一步解释

#### 2、解释网络延迟、GC问题
之后，Antirez对于对方提出的，网络延迟、进程GC可能导致Redlock失效的问题，也做了反驳。Redis作者提到，这个假设其实是有问题的，Redlock是可以保证锁安全的。这是怎么回事呢？还记得前面介绍Redlock流程的那5步吗？

<center><image src="../../../../img/distributed/redis_red_lock.png" width="60%" height="60%"/></center>

1. 客户端先获取**当前时间戳T1**
2. 客户端依次向这5个Redis实例发起加锁请求，且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个Redis实例申请加锁
3. 如果客户端从 >= 3个（大多数）Redis 实例上加锁成功，则再次获取**当前时间戳T2**，如果 T2 - T1 < 锁的过期时间。此时，认为客户端加锁成功，否则认为加锁失败
4. 加锁成功，则执行业务逻辑操作
5. 加锁失败，则向**全部节点**发起释放锁请求（前面讲到的Lua脚本先判断再释放锁）

这里的重点在于步骤3，加锁成功后为什么要重新获取当前时间戳T2？还用T2-T1的时间，与锁的过期时间做比较？
Antirez 强调：如果在1-3步发生了网络延迟、进程GC等耗时长的异常情况，那在第3步 T2 - T1，是可以检测出来的，如果超出了锁设置的过期时间，那这时就认为加锁会失败，之后释放所有节点的锁就好了！
如果发生网络延迟、进程 GC 是在步骤3之后，也就是客户端确认拿到了锁，去操作共享资源的途中发生了问题，导致锁失效，那这不止是 Redlock 的问题，任何其它锁服务例如 Zookeeper，都有类似的问题
Antirez 这里的结论就是：
+ **客户端在拿到锁之前，无论经历什么耗时长问题，Redlock 都能够在第3步检测出来**
+ **客户端在拿到锁之后，发生NPC，那 Redlock、Zookeeper 都无能为力**

所以，Redis 作者 Antirez 认为 Redlock 在保证时钟正确的基础上，是可以保证正确性的

#### 3、质疑fencing token机制
Redis 作者 Antirez 对于对方提出的 fecing token 机制，也提出了质疑，主要分为 2 个问题

**第一，这个方案必须要求要操作的「共享资源服务器」有拒绝「旧 token」的能力。**
例如，要操作 MySQL，从锁服务拿到一个递增数字的 token，然后客户端要带着这个 token 去改 MySQL 的某一行，这就需要利用 MySQL 的**事物隔离性**来做。
```sql
-- 两个客户端必须利用事物和隔离性达到目的
-- 注意 token 的判断条件
UPDATE table T SET val = $new_val, current_token = $token WHERE id = $id AND current_token < $token
```

但如果操作的不是 MySQL 呢？例如向磁盘上写一个文件，或发起一个 HTTP 请求，那这个方案就无能为力了，这对要操作的资源服务器，提出了更高的要求。
也就是说，大部分要操作的资源服务器，都是没有这种互斥能力的。再者，既然资源服务器都有了「互斥」能力，那还要分布式锁干什么？
所以，Redis 作者认为这个方案是站不住脚的。

**第二，退一步讲，即使 Redlock 没有提供 fecing token 的能力，但 Redlock 已经提供了随机值（就是前面讲的唯一标识），利用这个唯一标识，也可以达到与 fecing token 同样的效果**
如何做呢？大概流程如下：
1. 客户端使用 Redlock 拿到锁
2. 客户端在操作共享资源之前，先把这个锁的 VALUE，在要操作的共享资源上做标记
3. 客户端处理业务逻辑，最后，在修改共享资源时，判断这个标记是否与之前一样，一样才修改（类似 CAS 的思路）

还是以 MySQL 为例，举个例子就是这样的：
1. 客户端使用 Redlock 拿到锁
2. 客户端要修改 MySQL 表中的某一行数据之前，先把锁的 VALUE 更新到这一行的某个字段中（这里假设为 current_token 字段）
3. 客户端处理业务逻辑
4. 客户端修改 MySQL 的这一行数据，把 VALUE 当做 WHERE 条件，再修改

```sql
UPDATE table T SET val = $new_val WHERE id = $id AND current_token = $redlock_value
```

可见，这种方案依赖 MySQL 的事物机制，也达到对方提到的 fecing token 一样的效果。但这里还有个小问题，**两个客户端通过这种方案，先「标记」再「检查+修改」共享资源，那这两个客户端的操作顺序无法保证啊？**
而用 Martin 提到的 fecing token，因为这个 token 是单调递增的数字，资源服务器可以拒绝小的 token 请求，保证了操作的「顺序性」！

Redis 作者对这问题做了不同的解释，他解释道：分布式锁的本质，是为了「互斥」，只要能保证两个客户端在并发时，一个成功，一个失败就好了，不需要关心「顺序性」。

> 前面 Martin 的质疑中，一直很关心这个顺序性问题，但 Redis 的作者的看法却不同

综上，Redis 作者的结论：

1. 作者同意对方关于**时钟跳跃**对 Redlock 的影响，但认为时钟跳跃是可以避免的，取决于基础设施和运维
2. Redlock 在设计时，充分考虑了 NPC 问题，在 Redlock 步骤 3 之前出现 NPC，可以保证锁的正确性，但在步骤 3 之后发生 NPC，不止是 Redlock 有问题，其它分布式锁服务同样也有问题，所以不在讨论范畴内

好，讲完了双方对于 Redis 分布式锁的争论，你可能也注意到了，Martin 在他的文章中，推荐使用 Zookeeper 实现分布式锁，认为它更安全，但事实确实如此吗？

## 二、Zookeeper实现
我们知道，Zookeeper 中的数据节点分为持久节点、临时节点和顺序节点三种类型，而我们可以通过操作临时数据节点来实现分布式锁，具体如下：
1. clientA 尝试创建临时数据节点 /lock
2. 成功则执行业务逻辑
3. 释放锁（删除临时节点）

临时数据节点除了会被客户端主动删除之外，也会在客户端断开连接的时候自动删除，客户端断开连接大概可以分为两种情况：
+ 客户端主动断开连接
+ 由于网络、GC 等原因导致客户端无法上报心跳，Zookeeper 认为客户端挂掉

临时数据节点在客户端断开连接的时候自动释放，可以有效的避免死锁的发生，但这个机制同时也带来了如下问题：

<center><img src="../../../../img/distributed/zookeeper_lock_process_pause.png" width="60%" height="60%" /></center>

1. clientA 创建 /lock 临时数据节点，占有锁
2. 因为网络、GC 等原因导致 clientA 与 Zookeeper 断开连接，Zookeeper 删除 /lock 节点
3. clientB 创建 /lock 临时数据节点，占有锁

可以看到当客户端和 Zookeeper 异常断开连接的时候，有可能存在多个客户端同时占有锁的情况，这也就是上面 Redis 作者反驳 Martin 时提到的：**客户端在拿到锁之后，发生NPC，那 RedLock、Zookeeper 都无能为力**

## 三、数据库实现
基于数据库实现分布式锁，其核心思想是利用数据库的**唯一索引**来实现互斥的效果。例如：
```sql
-- 表结构定义
create table `distributed_lock` (
  id int auto_increment primary key,
  lock_val int not null default 0,
  unique index uidx(lock_val)
) engine=InnoDB;

-- 加锁语句
insert into `distributed_lock`(lock_val) values(4);

-- 解锁语句
delete from `distributed_lock` where lock_val = 4;
```

因为我们对 lock_val 做了唯一性约束，所以当有多个客户端同时提交加锁语句至数据库的话，数据库会保证只有一个请求能够成功。

但是在我们的日常使用中，基本上不会用数据库来实现分布式锁，主要有以下几点原因：
+ 性能：相对于 Redis、Zookeeper 来说，数据库实现的分布式锁性能较低
+ 数据库资源相对来说比较珍贵，不应该把它用在这些地方
+ 分布式锁的一些基本要求实现起来更加复杂，例如：
  + 锁失效机制
  + 阻塞特性
  + 可重入

## 四、总结

### 到底要不要用Redlock
前面也分析了，Redlock 只有建立在**时钟正确**的前提下，才能正常工作，如果你可以保证这个前提，那么可以拿来使用。但是保证时钟正确却不是那么简单：
+ 首先从硬件角度来说，时钟偏移时有发生，无法避免，例如 CPU 温度、机器负载、芯片材料等影响
+ 其次，人为暴力修改时钟，也时有发生

所以个人的看法是尽量不要使用，而且 Redlock 的性能也不及单机版 Redis，部署成本也高。

### 正确使用分布式锁
+ **使用分布式锁，在上层完成**互斥**目的，虽然极端情况下锁会失效，但它可以最大程度把并发请求阻挡在最上层，减轻操作资源层的压力**
+ **但对于要求数据绝对正确的业务，在资源层一定要做好「兜底」，设计思路可以借鉴 fecing token 的方案来做**

> 参考
  [深度剖析：Redis分布式锁到底安全吗？看完这篇文章彻底懂了！](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247485739&idx=1&sn=1401aba7c5816cf9c5230a28e2e7f2a3&chksm=e8bebe9edfc93788a330364c416f2f07840f4a1e9a2d3c6c788e1283f7fe5bd7aa703d4fa5af&scene=178&cur_album_id=1904080860136390658#rd)
  推荐阅读：
  [计算机时间到底是怎么来的？程序员必看的时间知识！](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247485900&idx=1&sn=a22ccc1754909845aeb74374b89a795a&chksm=e8bebe79dfc9376f646f92a730027e0b2fb80fa65aa24a565ee416671908b1798e90ac67a805&scene=178&cur_album_id=1580920500392869888#rd)